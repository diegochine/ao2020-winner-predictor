{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Australian Open 2020: Winner Predictor\n",
    "## Web Intelligence Course, Ca' Foscari University, A.Y. 2019/2020\n",
    "#### Diego Chinellato, 867637 - Giorgia Campardo, 867928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = {\n",
    "    'ATP': int,\n",
    "    'Location': object,\n",
    "    'Tournament': object,\n",
    "    'Series': object,\n",
    "    'Court': object,\n",
    "    'Surface': object,\n",
    "    'Round': object,\n",
    "    'Best of': int,\n",
    "    'Winner': object,\n",
    "    'Loser': object,\n",
    "    'WRank': float,\n",
    "    'LRank': float,\n",
    "    'WPts': float,\n",
    "    'LPts': float,\n",
    "    'W1': float,\n",
    "    'L1': float,\n",
    "    'W2': float,\n",
    "    'L2': float,\n",
    "    'W3': float,\n",
    "    'L3': float,\n",
    "    'W4': float,\n",
    "    'L4': float,\n",
    "    'W5': float,\n",
    "    'L5': float,\n",
    "    'Wsets': float,\n",
    "    'Lsets': float,\n",
    "    'Comment': object,\n",
    "    'B365W': float,\n",
    "    'B365L': float,\n",
    "    'EXW': object,\n",
    "    'EXL': float,\n",
    "    'LBW': float,\n",
    "    'LBL': float,\n",
    "    'PSW': float,\n",
    "    'PSL': float,\n",
    "    'SJW': float,\n",
    "    'SJL': float,\n",
    "    'MaxW': float,\n",
    "    'MaxL': float,\n",
    "    'AvgW': float,\n",
    "    'AvgL': float,\n",
    "    'WElo': float,\n",
    "    'WSurfElo': float,\n",
    "    'WHand': object,\n",
    "    'WBHand': float,\n",
    "    'LElo': float,\n",
    "    'LSurfElo': float,\n",
    "    'LHand': object,\n",
    "    'LBHand': float\n",
    "}\n",
    "x = pd.read_csv('data/dataset.csv', \n",
    "                encoding='utf-8-sig', \n",
    "                dtype=data_types,\n",
    "                parse_dates=['Date', 'WBD', 'LBD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L' 'R' nan]\n",
      "[nan 'R' 'L']\n",
      "[ 1.  2. nan]\n",
      "[nan  2.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(x['WHand'].unique())\n",
    "print(x['LHand'].unique())\n",
    "print(x['WBHand'].unique())\n",
    "print(x['LBHand'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_elo_rankings(data):\n",
    "    \"\"\"\n",
    "    Given the list on matches in chronological order, for each match, computes \n",
    "    the elo ranking of the 2 players at the beginning of the match\n",
    "    \"\"\"\n",
    "    print(\"Elo rankings computing...\")\n",
    "    players=list(pd.Series(list(data.Winner)+list(data.Loser)).value_counts().index)\n",
    "    elo=pd.Series(np.ones(len(players))*1500,index=players)\n",
    "    ranking_elo=[(1500,1500)]\n",
    "    for i in range(1,len(data)):\n",
    "        w=data.iloc[i-1,:].Winner\n",
    "        l=data.iloc[i-1,:].Loser\n",
    "        elow=elo[w]\n",
    "        elol=elo[l]\n",
    "        pwin=1 / (1 + 10 ** ((elol - elow) / 400))    \n",
    "        K_win=32\n",
    "        K_los=32\n",
    "        new_elow=elow+K_win*(1-pwin)\n",
    "        new_elol=elol-K_los*(1-pwin)\n",
    "        elo[w]=new_elow\n",
    "        elo[l]=new_elol\n",
    "        ranking_elo.append((elo[data.iloc[i,:].Winner],elo[data.iloc[i,:].Loser])) \n",
    "    ranking_elo=pd.DataFrame(ranking_elo,columns=[\"elo_winner\",\"elo_loser\"])    \n",
    "    ranking_elo[\"proba_elo\"]=1 / (1 + 10 ** ((ranking_elo[\"elo_loser\"] - ranking_elo[\"elo_winner\"]) / 400))   \n",
    "    return ranking_elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(max_date=2014,\n",
    "                    features_to_drop=[], \n",
    "                    missing_values=\"drop\", \n",
    "                    drop_first=False):\n",
    "    \"\"\"\n",
    "    Processes raw data and returns a tuple (X, Y) where X is the cleaned dataset and Y is the array of labels.\n",
    "    \"\"\"\n",
    "    if max_date > 2019 or max_date < 2011:\n",
    "        raise ValueError(\"Wrong date parameter\")\n",
    "    df = pd.read_csv(\"data/\" + str(max_date) + \".csv\", encoding='utf-8-sig')\n",
    "    for year in range (max_date + 1, 2020):\n",
    "        filename = \"data/\" + str(year) + \".csv\"\n",
    "        df = pd.concat((df, pd.read_csv(filename, encoding='utf-8-sig', dtype=data_types)))\n",
    "    \n",
    "    # Sort by date to calculate ELO\n",
    "    X = df.sort_values(by='Date')\n",
    "    \n",
    "    # Drop unuseful columns\n",
    "    features_to_drop += ['ATP', 'Location', 'Tournament', 'Date', 'Comment', \n",
    "                         'WPts', 'LPts', 'Wsets', 'Lsets', \n",
    "                         'W1', 'L1', 'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', \n",
    "                         'B365W', 'B365L', 'EXW', 'EXL', 'LBW', 'LBL', 'PSW', 'PSL', 'SJW', 'SJL',\n",
    "                         'WBD', 'LBD']\n",
    "    X = X.drop(columns=features_to_drop)\n",
    "    \n",
    "    # Deal with missing values\n",
    "    X['WRank'] = X['WRank'].fillna(value=X['WRank'].max()+100).astype(int)\n",
    "    X['LRank'] = X['LRank'].fillna(value=X['LRank'].max()+100).astype(int)\n",
    "\n",
    "    if missing_values == 'drop':\n",
    "        X = X.dropna()\n",
    "    elif missing_values == 'custom':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Wrong parameter: missing_values')\n",
    "\n",
    "    # Convert ordinal features to int (higher value means more important)\n",
    "    series = ['ATP250', 'ATP500', 'Masters 1000', 'Masters Cup', 'Grand Slam']\n",
    "    series2int = {s: i for i, s in enumerate(series)}\n",
    "    rounds2int = {'1st Round': 0,\n",
    "                  '2nd Round': 1,\n",
    "                  '3rd Round': 2,\n",
    "                  '4th Round': 3,\n",
    "                  'Round Robin': 4,\n",
    "                  'Quarterfinals': 5,\n",
    "                  'Semifinals': 6,\n",
    "                  'The Final': 7,\n",
    "                 }\n",
    "    X = X.replace({'Round': rounds2int, 'Series': series2int})\n",
    "    \n",
    "    # Convert categorical (binary) fields to int\n",
    "    X = X.replace({'Court': {'Outdoor': 0, 'Indoor': 1}, \n",
    "                   'WHand': {'R': 0, 'L': 1}, \n",
    "                   'LHand': {'R': 0, 'L': 1}})\n",
    "    X.astype({'WBHand': int, 'LBHand': int})\n",
    "    \n",
    "    # One hot encode categorical features into binary features\n",
    "    X = pd.get_dummies(X, prefix=['Surface_'], columns=['Surface'], drop_first=drop_first)\n",
    "    \n",
    "    # Convert players to numeric ?\n",
    "    players = set(X['Winner']) | set(X['Loser'])\n",
    "    players_to_id = {}\n",
    "    for i, player in enumerate(players):\n",
    "        players_to_id[player] = i\n",
    "    X = X.replace({'Winner': players_to_id, 'Loser': players_to_id})\n",
    "    X = X.astype({'Winner': int, 'Loser': int})\n",
    "\n",
    "    X = X.rename(columns={'Winner':'1st Player', 'Loser':'2nd Player', \n",
    "                          'WRank':'P1Rank', 'LRank':'P2Rank', \n",
    "                          'MaxW':'MaxP1', 'MaxL':'MaxP2', \n",
    "                          'AvgW':'AvgP1', 'AvgL':'AvgP2'})\n",
    "    \n",
    "    # Generate labels\n",
    "    Y = np.concatenate([np.ones(X.shape[0], dtype=int), np.zeros(X.shape[0], dtype=int)])\n",
    "    # Swap columns and concatenate to data\n",
    "    tmp = X.copy()\n",
    "    cols_to_swap = ['1st Player', '2nd Player', 'P1Rank', 'P2Rank', 'MaxP1', 'MaxP2',  'AvgP1',  'AvgP2',\n",
    "                    'WElo', 'LElo', 'WSurfElo', 'LSurfElo', 'WHand', 'LHand', 'WBHand', 'LBHand']\n",
    "    cols_swapped = ['2nd Player', '1st Player', 'P2Rank', 'P1Rank', 'MaxP2', 'MaxP1',  'AvgP2',  'AvgP1', \n",
    "                    'LElo', 'WElo', 'LSurfElo', 'WSurfElo', 'LHand', 'WHand', 'LBHand', 'WBHand']\n",
    "\n",
    "    tmp[cols_to_swap] = tmp[cols_swapped]\n",
    "    tmp.index = np.array(range(X.shape[0] + 1, X.shape[0] * 2 + 1))\n",
    "    X = pd.concat((X, tmp))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6684 entries, 0 to 6684\n",
      "Data columns (total 23 columns):\n",
      "Series            6684 non-null int64\n",
      "Court             6684 non-null int64\n",
      "Round             6684 non-null int64\n",
      "Best of           6684 non-null int64\n",
      "1st Player        6684 non-null int32\n",
      "2nd Player        6684 non-null int32\n",
      "P1Rank            6684 non-null int32\n",
      "P2Rank            6684 non-null int32\n",
      "MaxP1             6684 non-null float64\n",
      "MaxP2             6684 non-null float64\n",
      "AvgP1             6684 non-null float64\n",
      "AvgP2             6684 non-null float64\n",
      "WElo              6684 non-null float64\n",
      "WSurfElo          6684 non-null float64\n",
      "WHand             6684 non-null int64\n",
      "WBHand            6684 non-null float64\n",
      "LElo              6684 non-null float64\n",
      "LSurfElo          6684 non-null float64\n",
      "LHand             6684 non-null int64\n",
      "LBHand            6684 non-null float64\n",
      "Surface__Clay     6684 non-null uint8\n",
      "Surface__Grass    6684 non-null uint8\n",
      "Surface__Hard     6684 non-null uint8\n",
      "dtypes: float64(10), int32(4), int64(6), uint8(3)\n",
      "memory usage: 1011.7 KB\n"
     ]
    }
   ],
   "source": [
    "X, Y = preprocess_data(max_date=2018)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>1st Player</th>\n",
       "      <th>2nd Player</th>\n",
       "      <th>P1Rank</th>\n",
       "      <th>P2Rank</th>\n",
       "      <th>MaxP1</th>\n",
       "      <th>MaxP2</th>\n",
       "      <th>...</th>\n",
       "      <th>WSurfElo</th>\n",
       "      <th>WHand</th>\n",
       "      <th>WBHand</th>\n",
       "      <th>LElo</th>\n",
       "      <th>LSurfElo</th>\n",
       "      <th>LHand</th>\n",
       "      <th>LBHand</th>\n",
       "      <th>Surface__Clay</th>\n",
       "      <th>Surface__Grass</th>\n",
       "      <th>Surface__Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>6684.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.430580</td>\n",
       "      <td>0.168761</td>\n",
       "      <td>1.529623</td>\n",
       "      <td>3.397965</td>\n",
       "      <td>101.961251</td>\n",
       "      <td>101.961251</td>\n",
       "      <td>67.120287</td>\n",
       "      <td>67.120287</td>\n",
       "      <td>2.857102</td>\n",
       "      <td>2.857102</td>\n",
       "      <td>...</td>\n",
       "      <td>1737.341427</td>\n",
       "      <td>0.151706</td>\n",
       "      <td>1.813435</td>\n",
       "      <td>1789.398668</td>\n",
       "      <td>1737.341427</td>\n",
       "      <td>0.151706</td>\n",
       "      <td>1.813435</td>\n",
       "      <td>0.285757</td>\n",
       "      <td>0.132555</td>\n",
       "      <td>0.581688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.500301</td>\n",
       "      <td>0.374569</td>\n",
       "      <td>2.082725</td>\n",
       "      <td>0.798530</td>\n",
       "      <td>63.159379</td>\n",
       "      <td>63.159379</td>\n",
       "      <td>83.225931</td>\n",
       "      <td>83.225931</td>\n",
       "      <td>3.142151</td>\n",
       "      <td>3.142151</td>\n",
       "      <td>...</td>\n",
       "      <td>153.533439</td>\n",
       "      <td>0.358762</td>\n",
       "      <td>0.389591</td>\n",
       "      <td>157.982929</td>\n",
       "      <td>153.533439</td>\n",
       "      <td>0.358762</td>\n",
       "      <td>0.389591</td>\n",
       "      <td>0.451808</td>\n",
       "      <td>0.339119</td>\n",
       "      <td>0.493319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>1223.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1298.200000</td>\n",
       "      <td>1223.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>1638.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1685.900000</td>\n",
       "      <td>1638.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>1727.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1783.200000</td>\n",
       "      <td>1727.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>1817.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1872.700000</td>\n",
       "      <td>1817.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>1921.000000</td>\n",
       "      <td>1921.000000</td>\n",
       "      <td>52.250000</td>\n",
       "      <td>52.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>2163.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2203.400000</td>\n",
       "      <td>2163.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Series        Court        Round      Best of   1st Player  \\\n",
       "count  6684.000000  6684.000000  6684.000000  6684.000000  6684.000000   \n",
       "mean      1.430580     0.168761     1.529623     3.397965   101.961251   \n",
       "std       1.500301     0.374569     2.082725     0.798530    63.159379   \n",
       "min       0.000000     0.000000     0.000000     3.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     3.000000    43.750000   \n",
       "50%       1.000000     0.000000     1.000000     3.000000   101.000000   \n",
       "75%       2.000000     0.000000     2.000000     3.000000   157.000000   \n",
       "max       4.000000     1.000000     7.000000     5.000000   214.000000   \n",
       "\n",
       "        2nd Player       P1Rank       P2Rank        MaxP1        MaxP2  ...  \\\n",
       "count  6684.000000  6684.000000  6684.000000  6684.000000  6684.000000  ...   \n",
       "mean    101.961251    67.120287    67.120287     2.857102     2.857102  ...   \n",
       "std      63.159379    83.225931    83.225931     3.142151     3.142151  ...   \n",
       "min       0.000000     1.000000     1.000000     1.010000     1.010000  ...   \n",
       "25%      43.750000    26.000000    26.000000     1.530000     1.530000  ...   \n",
       "50%     101.000000    51.000000    51.000000     2.010000     2.010000  ...   \n",
       "75%     157.000000    88.000000    88.000000     2.950000     2.950000  ...   \n",
       "max     214.000000  1921.000000  1921.000000    52.250000    52.250000  ...   \n",
       "\n",
       "          WSurfElo        WHand       WBHand         LElo     LSurfElo  \\\n",
       "count  6684.000000  6684.000000  6684.000000  6684.000000  6684.000000   \n",
       "mean   1737.341427     0.151706     1.813435  1789.398668  1737.341427   \n",
       "std     153.533439     0.358762     0.389591   157.982929   153.533439   \n",
       "min    1223.400000     0.000000     1.000000  1298.200000  1223.400000   \n",
       "25%    1638.500000     0.000000     2.000000  1685.900000  1638.500000   \n",
       "50%    1727.200000     0.000000     2.000000  1783.200000  1727.200000   \n",
       "75%    1817.900000     0.000000     2.000000  1872.700000  1817.900000   \n",
       "max    2163.500000     1.000000     2.000000  2203.400000  2163.500000   \n",
       "\n",
       "             LHand       LBHand  Surface__Clay  Surface__Grass  Surface__Hard  \n",
       "count  6684.000000  6684.000000    6684.000000     6684.000000    6684.000000  \n",
       "mean      0.151706     1.813435       0.285757        0.132555       0.581688  \n",
       "std       0.358762     0.389591       0.451808        0.339119       0.493319  \n",
       "min       0.000000     1.000000       0.000000        0.000000       0.000000  \n",
       "25%       0.000000     2.000000       0.000000        0.000000       0.000000  \n",
       "50%       0.000000     2.000000       0.000000        0.000000       1.000000  \n",
       "75%       0.000000     2.000000       1.000000        0.000000       1.000000  \n",
       "max       1.000000     2.000000       1.000000        1.000000       1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the baseline model is: 0.37\n"
     ]
    }
   ],
   "source": [
    "def baseline_model(X, Y):\n",
    "    # This model will always predict the winner as the player with the highest rank.\n",
    "    # It's the lower bound on accuracy that we wish to improve\n",
    "    y_pred = (X['P1Rank'] > X['P2Rank']).astype(int)\n",
    "    accuracy = round((y_pred == Y).sum()/len(Y), 2)\n",
    "    return accuracy\n",
    "    \n",
    "print('Accuracy for the baseline model is:', baseline_model(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(X_train, Y_train, X_valid, Y_valid):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    # Builds a decision tree and performs automatic hyper-parameters tuning\n",
    "    scores = []\n",
    "    for criterion in ('gini', 'entropy'):\n",
    "        for depth in range(5, 50, 5):\n",
    "            for leaves in range(10, 201, 30):\n",
    "                dt = DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                            criterion=criterion,\n",
    "                                            max_depth=depth)\n",
    "                dt.fit(X_train, Y_train)\n",
    "                valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=dt.predict(X_valid)), 3)\n",
    "                scores += [(valid_acc, criterion, depth, leaves)]\n",
    "    best = max(scores)\n",
    "    acc, criterion, depth, leaves = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('Criterion:', criterion)\n",
    "    print('Max depth:', depth)\n",
    "    print('Max leaves:', leaves)\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                 criterion=criterion,\n",
    "                                 max_depth=depth)\n",
    "    dt.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bagging_classifier(X_train, Y_train, X_valid, Y_valid):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    scores = []\n",
    "    for bootstrap in (True, False):\n",
    "        for n_est in range(10, 201, 20):\n",
    "            for max_samples in (0.25, 0.50, 0.75, 1.0):\n",
    "                for criterion in ('gini', 'entropy'):\n",
    "                    dt = DecisionTreeClassifier(criterion=criterion)\n",
    "                    bagged_dt = BaggingClassifier(dt, bootstrap=bootstrap,\n",
    "                                                  n_estimators=n_est,\n",
    "                                                  max_samples=max_samples,\n",
    "                                                  n_jobs=-1)\n",
    "                    bagged_dt.fit(X_train, Y_train)\n",
    "                    valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=bagged_dt.predict(X_valid)), 3)\n",
    "                    scores += [(valid_acc, bootstrap, n_est, max_samples, criterion)]\n",
    "    best = max(scores)\n",
    "    acc, bootsrap, n_est, max_samples, criterion = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('Boostrap:', bootsrap)\n",
    "    print('N. estimators:', n_est)\n",
    "    print('Max samples:', max_samples)\n",
    "    print('Tree criterion:', criterion)\n",
    "    bagged_dt = BaggingClassifier(dt, \n",
    "                                  bootstrap=bootstrap,\n",
    "                                  n_estimators=n_est, \n",
    "                                  max_samples=max_samples)\n",
    "    bagged_dt.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return bagged_dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adaboost(X_train, Y_train, X_valid, Y_valid):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    scores = []\n",
    "    for n_est in range(50, 301, 25):\n",
    "        for learning_rate in (0.50, 0.75, 1.0, 1.5):\n",
    "            for criterion in ('gini', 'entropy'):\n",
    "                for depth in range(5, 26, 5):\n",
    "                    for leaves in range(5, 100, 15):\n",
    "                        dt = DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                                    criterion=criterion,\n",
    "                                                    max_depth=depth)\n",
    "                        boosted_dt = AdaBoostClassifier(dt,\n",
    "                                                        n_estimators=n_est,\n",
    "                                                        learning_rate=learning_rate)\n",
    "                        boosted_dt.fit(X_train, Y_train)\n",
    "                        valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=bagged_dt.predict(X_valid)), 3)\n",
    "                        scores += [(valid_acc, n_est, learning_rate, leaves, criterion, depth)]\n",
    "    best = max(scores)\n",
    "    acc, n_est, learning_rate, leaves, criterion, depth = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('N. estimators:', n_est)\n",
    "    print('Learning rate:', learning_rate)\n",
    "    print('Tree max leaves:', leaves)\n",
    "    print('Tree max depth:', depth)\n",
    "    print('Tree criterion:', criterion)\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                criterion=criterion,\n",
    "                                max_depth=depth)\n",
    "    boosted_dt = AdaBoostClassifier(dt,\n",
    "                                    n_estimators=n_est,\n",
    "                                    learning_rate=learning_rate)\n",
    "    boosted_dt.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return boosted_dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_forest(X_train, Y_train, X_valid, Y_valid):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    scores = []\n",
    "    for n_est in range(50, 501, 50):\n",
    "        for criterion in ('gini', 'entropy'):\n",
    "            for bootstrap in (True, False):\n",
    "                for n_features in (None, 'sqrt', 'log2'):\n",
    "                    rf = RandomForestClassifier(n_estimators=n_est,\n",
    "                                                bootstrap=bootstrap,\n",
    "                                                criterion=criterion,\n",
    "                                                max_features=n_features,\n",
    "                                                n_jobs=-1)\n",
    "                    rf.fit(X_train, Y_train)\n",
    "                    valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=rf.predict(X_valid)), 3)\n",
    "                    scores += [(valid_acc, n_est, criterion, bootstrap, n_features)]\n",
    "    best = max(scores)\n",
    "    acc, n_est, criterion, bootstrap, features = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('N. estimators:', n_est)\n",
    "    print('Criterion:', criterion)\n",
    "    print('Bootstrap:', bootstrap)\n",
    "    print('Features criterion (None means all features):', features)\n",
    "    rf = RandomForestClassifier(n_estimators=n_est,\n",
    "                               bootstrap=bootstrap,\n",
    "                               criterion=criterion,\n",
    "                               n_jobs=-1)\n",
    "    rf.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return rf, best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train set, validation set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.67\n",
      "Criterion: gini\n",
      "Max depth: 5\n",
      "Max leaves: 160\n"
     ]
    }
   ],
   "source": [
    "dt, dt_params = build_decision_tree(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.675\n",
      "Boostrap: False\n",
      "N. estimators: 30\n",
      "Max samples: 0.25\n",
      "Tree criterion: entropy\n"
     ]
    }
   ],
   "source": [
    "bagged_dt, bagged_params = build_bagging_classifier(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-f7ba7ddbbe77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mboosted_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboosted_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_adaboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-141-a2153b4b8f63>\u001b[0m in \u001b[0;36mbuild_adaboost\u001b[1;34m(X_train, Y_train, X_valid, Y_valid)\u001b[0m\n\u001b[0;32m     14\u001b[0m                                                         \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_est\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                                                         learning_rate=learning_rate)\n\u001b[1;32m---> 16\u001b[1;33m                         \u001b[0mboosted_dt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                         \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbagged_dt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                         \u001b[0mscores\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_est\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleaves\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                 random_state)\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    484\u001b[0m         \"\"\"\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "boosted_dt, boosted_params = build_adaboost(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.683\n",
      "N. estimators: 100\n",
      "Criterion: entropy\n",
      "Bootstrap: False\n",
      "Features criterion (None means all features): sqrt\n"
     ]
    }
   ],
   "source": [
    "rf, rf_params = build_random_forest(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(X, Y, models):\n",
    "    for model in models:\n",
    "        print('Algorithm:', str(type(model)).split('.')[-1][:-2])\n",
    "        rep = classification_report(y_true=Y, y_pred=model.predict(X))\n",
    "        print(rep)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69       688\n",
      "           1       0.67      0.74      0.70       649\n",
      "\n",
      "    accuracy                           0.70      1337\n",
      "   macro avg       0.70      0.70      0.70      1337\n",
      "weighted avg       0.70      0.70      0.70      1337\n",
      "\n",
      "\n",
      "Algorithm: BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       688\n",
      "           1       0.81      0.76      0.79       649\n",
      "\n",
      "    accuracy                           0.80      1337\n",
      "   macro avg       0.80      0.80      0.80      1337\n",
      "weighted avg       0.80      0.80      0.80      1337\n",
      "\n",
      "\n",
      "Algorithm: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66       688\n",
      "           1       0.64      0.65      0.65       649\n",
      "\n",
      "    accuracy                           0.65      1337\n",
      "   macro avg       0.65      0.65      0.65      1337\n",
      "weighted avg       0.65      0.65      0.65      1337\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(X_test, Y_test, [dt, bagged_dt, boosted_dt, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
